{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "imagem \n",
      "\n",
      "Temos a seguinte classe que representa um usuário no nosso sistema:\n",
      "\n",
      "java\n",
      "\n",
      "Para salvar um novo usuário, várias validações são feitas, como por exemplo: Ver se o nome só contém letras, [**o CPF só números**] e ver se o usuário possui no mínimo 18 anos. Veja o método que faz essa validação:\n",
      "\n",
      "java \n",
      "\n",
      "Suponha agora que eu tenha outra classe, a classe `Produto`, que contém um atributo nome e eu quero fazer a mesma validação que fiz para o nome do usuário: Ver se só contém letras. E aí? Vou\n"
     ]
    }
   ],
   "source": [
    "# with ... as ...: permite determinar comandos que trabalhem com um determinado arquivo.\n",
    "with open('./corretor-master/artigos.txt', 'r', encoding = 'UTF-8') as f: # open() função nativa do python que recebe um arquivo e um modo (r = read = leitura) como parâmetros.\n",
    "    articles = f.read() # armazenando a leitura do arquivo aberto em articles\n",
    "\n",
    "print(articles[:500]) # printando apenas os primeiros 500 caracteres de articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2605046"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles) # len() irá retornar o número total de caracteres presentes nas strings de articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olá,', 'tudo', 'bem?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text = 'Olá, tudo bem?'\n",
    "separate_words = example_text.split() # o método de strings .split() separa as partes de uma string em uma lista.\n",
    "separate_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em NLP, as partes de um texto (palavras) são chamadas de *tokens*. Token é uma sequência de caracteres, separados por um limitador, que pode ser um espaço em branco, pontuação ou quebra de linhas, por exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olá,', 'tudo', 'bem?']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text = 'Olá, tudo bem?'\n",
    "tokens = example_text.split()\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yalel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk as nltk # lib que possui métodos de tratamento de tokens\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olá', ',', 'tudo', 'bem', '?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separate_words = nltk.tokenize.word_tokenize(example_text) # método que irá separar as palavras das acentuações dos tokens\n",
    "separate_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(separate_words) # nesse caso, o retorno será 5 pois leva em consideração as pontuações separadas que estão no array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_words(tokens_list): # criando uma função que irá verificar no array de strings quais caracteres são alfabéticos para retirar as pontuações e números. Dessa forma, as palavras alfabéticas serão adicionadas em um novo array.\n",
    "    words_list = []\n",
    "    for token in tokens_list:\n",
    "        if token.isalpha(): # o método de string .isalpha() percorre os caracteres de strings retornando True se ele for alfabético e False se for um número ou pontuação.\n",
    "            words_list.append(token)\n",
    "    return words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olá', 'tudo', 'bem']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divide_words(separate_words) # testando a função com a lista de tokens criada previamente como teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_tokens = nltk.tokenize.word_tokenize(articles)\n",
    "words_list = divide_words(articles_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O número de palavras do arquivo artigos.txt é 403031\n"
     ]
    }
   ],
   "source": [
    "len(words_list)\n",
    "print(f'O número de palavras do arquivo artigos.txt é {len(words_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imagem', 'Temos', 'a', 'seguinte', 'classe']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(words_list): # criando uma função que irá normalizar as palavras de uma lista de palavras colocando todas as letras em minúsculo.\n",
    "    normalized_list = []\n",
    "    for word in words_list:\n",
    "        normalized_list.append(word.lower())\n",
    "    return normalized_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_list = normalization(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imagem', 'temos', 'a', 'seguinte', 'classe']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5, 6}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([1, 1, 2, 2, 2, 3, 3, 4, 5, 5, 6]) # set() é um método que percorre os valores de uma lista retornando um dict com os valores únicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18464"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(normalized_list)) # número de tipos de palavras diferentes encontradas no corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('l', 'gica')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = 'lgica'\n",
    "(list[:1], list[1:]) # as strings podem ser separadas utilizando métodos de listas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo o algoritmo que irá receber uma palavra, 'fatiar\" a palavra recebida, inserir e cada uma das letras do alfabeto nessas partições."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['algica', 'blgica', 'clgica', 'dlgica', 'elgica', 'flgica', 'glgica', 'hlgica', 'ilgica', 'jlgica', 'klgica', 'llgica', 'mlgica', 'nlgica', 'olgica', 'plgica', 'qlgica', 'rlgica', 'slgica', 'tlgica', 'ulgica', 'vlgica', 'wlgica', 'xlgica', 'ylgica', 'zlgica', 'àlgica', 'álgica', 'âlgica', 'ãlgica', 'èlgica', 'élgica', 'êlgica', 'ìlgica', 'ílgica', 'îlgica', 'òlgica', 'ólgica', 'ôlgica', 'õlgica', 'ùlgica', 'úlgica', 'ûlgica', 'çlgica', 'lagica', 'lbgica', 'lcgica', 'ldgica', 'legica', 'lfgica', 'lggica', 'lhgica', 'ligica', 'ljgica', 'lkgica', 'llgica', 'lmgica', 'lngica', 'logica', 'lpgica', 'lqgica', 'lrgica', 'lsgica', 'ltgica', 'lugica', 'lvgica', 'lwgica', 'lxgica', 'lygica', 'lzgica', 'làgica', 'lágica', 'lâgica', 'lãgica', 'lègica', 'légica', 'lêgica', 'lìgica', 'lígica', 'lîgica', 'lògica', 'lógica', 'lôgica', 'lõgica', 'lùgica', 'lúgica', 'lûgica', 'lçgica', 'lgaica', 'lgbica', 'lgcica', 'lgdica', 'lgeica', 'lgfica', 'lggica', 'lghica', 'lgiica', 'lgjica', 'lgkica', 'lglica', 'lgmica', 'lgnica', 'lgoica', 'lgpica', 'lgqica', 'lgrica', 'lgsica', 'lgtica', 'lguica', 'lgvica', 'lgwica', 'lgxica', 'lgyica', 'lgzica', 'lgàica', 'lgáica', 'lgâica', 'lgãica', 'lgèica', 'lgéica', 'lgêica', 'lgìica', 'lgíica', 'lgîica', 'lgòica', 'lgóica', 'lgôica', 'lgõica', 'lgùica', 'lgúica', 'lgûica', 'lgçica', 'lgiaca', 'lgibca', 'lgicca', 'lgidca', 'lgieca', 'lgifca', 'lgigca', 'lgihca', 'lgiica', 'lgijca', 'lgikca', 'lgilca', 'lgimca', 'lginca', 'lgioca', 'lgipca', 'lgiqca', 'lgirca', 'lgisca', 'lgitca', 'lgiuca', 'lgivca', 'lgiwca', 'lgixca', 'lgiyca', 'lgizca', 'lgiàca', 'lgiáca', 'lgiâca', 'lgiãca', 'lgièca', 'lgiéca', 'lgiêca', 'lgiìca', 'lgiíca', 'lgiîca', 'lgiòca', 'lgióca', 'lgiôca', 'lgiõca', 'lgiùca', 'lgiúca', 'lgiûca', 'lgiçca', 'lgicaa', 'lgicba', 'lgicca', 'lgicda', 'lgicea', 'lgicfa', 'lgicga', 'lgicha', 'lgicia', 'lgicja', 'lgicka', 'lgicla', 'lgicma', 'lgicna', 'lgicoa', 'lgicpa', 'lgicqa', 'lgicra', 'lgicsa', 'lgicta', 'lgicua', 'lgicva', 'lgicwa', 'lgicxa', 'lgicya', 'lgicza', 'lgicàa', 'lgicáa', 'lgicâa', 'lgicãa', 'lgicèa', 'lgicéa', 'lgicêa', 'lgicìa', 'lgicía', 'lgicîa', 'lgicòa', 'lgicóa', 'lgicôa', 'lgicõa', 'lgicùa', 'lgicúa', 'lgicûa', 'lgicça', 'lgicaa', 'lgicab', 'lgicac', 'lgicad', 'lgicae', 'lgicaf', 'lgicag', 'lgicah', 'lgicai', 'lgicaj', 'lgicak', 'lgical', 'lgicam', 'lgican', 'lgicao', 'lgicap', 'lgicaq', 'lgicar', 'lgicas', 'lgicat', 'lgicau', 'lgicav', 'lgicaw', 'lgicax', 'lgicay', 'lgicaz', 'lgicaà', 'lgicaá', 'lgicaâ', 'lgicaã', 'lgicaè', 'lgicaé', 'lgicaê', 'lgicaì', 'lgicaí', 'lgicaî', 'lgicaò', 'lgicaó', 'lgicaô', 'lgicaõ', 'lgicaù', 'lgicaú', 'lgicaû', 'lgicaç']\n"
     ]
    }
   ],
   "source": [
    "example_word = 'lgica'\n",
    "\n",
    "def insert_letters(detached_word):\n",
    "    new_words = []\n",
    "    alphabet = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for left_side, right_side in detached_word:\n",
    "        for letter in alphabet:\n",
    "            new_words.append(left_side + letter + right_side) \n",
    "    return new_words\n",
    "\n",
    "def word_generator(word):\n",
    "    detached_word = []\n",
    "    for i in range(len(word) + 1): # adiciona-se o +1 para poder incluir o último item da lista na separação.\n",
    "        detached_word.append((word[:i], word[i:]))\n",
    "    \n",
    "    generated_words = insert_letters(detached_word)\n",
    "    return generated_words\n",
    "\n",
    "generated_words = word_generator(example_word)\n",
    "print(generated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrector(word):\n",
    "    generated_words = word_generator(word)\n",
    "    correct_word = max(generated_words, key = probability)\n",
    "    return correct_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('de', 15502),\n",
       " ('o', 14056),\n",
       " ('que', 12230),\n",
       " ('a', 11099),\n",
       " ('e', 10501),\n",
       " ('para', 7710),\n",
       " ('um', 6367),\n",
       " ('é', 5899),\n",
       " ('uma', 5220),\n",
       " ('do', 5124)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words = len(normalized_list)\n",
    "frequency = nltk.FreqDist(normalized_list) # calcula a distribuição de frequência das palavras (tokens).\n",
    "frequency.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00023819507680550628"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def probability(generated_words): # função que calcula a probabilidade da palavra ser selecionada no corpus\n",
    "    return frequency[generated_words] / total_words\n",
    "\n",
    "probability('lógica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrector(example_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('podemos', 'pyodemos'),\n",
       " ('esse', 'esje'),\n",
       " ('já', 'jrá'),\n",
       " ('nosso', 'nossov'),\n",
       " ('são', 'sãêo'),\n",
       " ('dos', 'dosa'),\n",
       " ('muito', 'muifo'),\n",
       " ('imagem', 'iômagem'),\n",
       " ('sua', 'ósua'),\n",
       " ('também', 'tambéùm'),\n",
       " ('ele', 'eme'),\n",
       " ('fazer', 'èazer'),\n",
       " ('temos', 'temfs'),\n",
       " ('essa', 'eàssa'),\n",
       " ('quando', 'quaôdo'),\n",
       " ('vamos', 'vamvos'),\n",
       " ('sobre', 'hsobre'),\n",
       " ('java', 'sjava'),\n",
       " ('das', 'daõs'),\n",
       " ('agora', 'agorah'),\n",
       " ('está', 'eòtá'),\n",
       " ('cada', 'céda'),\n",
       " ('mesmo', 'zmesmo'),\n",
       " ('nos', 'noâ'),\n",
       " ('forma', 'fobma'),\n",
       " ('seja', 'sejéa'),\n",
       " ('então', 'enêão'),\n",
       " ('criar', 'èriar'),\n",
       " ('código', 'cóeigo'),\n",
       " ('caso', 'casío'),\n",
       " ('exemplo', 'áexemplo'),\n",
       " ('tem', 'tĩem'),\n",
       " ('usuário', 'usuárôio'),\n",
       " ('dados', 'dfados'),\n",
       " ('python', 'pgthon'),\n",
       " ('nossa', 'nossah'),\n",
       " ('além', 'alémè'),\n",
       " ('assim', 'asõim'),\n",
       " ('ter', 'teb'),\n",
       " ('até', 'atĩ'),\n",
       " ('bem', 'âem'),\n",
       " ('design', 'desigen'),\n",
       " ('trabalho', 'trabalàho'),\n",
       " ('foi', 'foo'),\n",
       " ('apenas', 'apenaũ'),\n",
       " ('empresa', 'empresà'),\n",
       " ('valor', 'valíor'),\n",
       " ('será', 'serr'),\n",
       " ('entre', 'entke'),\n",
       " ('método', 'méqodo'),\n",
       " ('precisamos', 'precisamops'),\n",
       " ('ainda', 'ainàa'),\n",
       " ('vai', 'van'),\n",
       " ('conteúdo', 'ûconteúdo'),\n",
       " ('seus', 'çeus'),\n",
       " ('eu', 'eû'),\n",
       " ('todos', 'todtos'),\n",
       " ('tempo', 'temeo'),\n",
       " ('sempre', 'semre'),\n",
       " ('qual', 'quakl'),\n",
       " ('ela', 'elaá'),\n",
       " ('só', 'síó'),\n",
       " ('utilizar', 'utiqizar'),\n",
       " ('projeto', 'prhojeto'),\n",
       " ('site', 'siàe'),\n",
       " ('sem', 'seém'),\n",
       " ('pelo', 'peln'),\n",
       " ('alura', 'aléra'),\n",
       " ('dia', 'tdia'),\n",
       " ('tudo', 'tuúo'),\n",
       " ('podemos', 'kpodemos'),\n",
       " ('esse', 'eẽsse'),\n",
       " ('já', 'jé'),\n",
       " ('nosso', 'nçosso'),\n",
       " ('são', 'sãô'),\n",
       " ('dos', 'odos'),\n",
       " ('muito', 'tuito'),\n",
       " ('imagem', 'imõgem'),\n",
       " ('sua', 'siua'),\n",
       " ('também', 'tamvbém'),\n",
       " ('ele', 'elpe'),\n",
       " ('fazer', 'façzer'),\n",
       " ('temos', 'teos'),\n",
       " ('essa', 'eũsa'),\n",
       " ('quando', 'quaìdo'),\n",
       " ('vamos', 'vjmos'),\n",
       " ('sobre', 'sxobre'),\n",
       " ('java', 'jkva'),\n",
       " ('das', 'dms'),\n",
       " ('agora', 'agtora'),\n",
       " ('está', 'esútá'),\n",
       " ('cada', 'cava'),\n",
       " ('mesmo', 'medmo'),\n",
       " ('nos', 'ános'),\n",
       " ('forma', 'forûa'),\n",
       " ('seja', 'smeja'),\n",
       " ('então', 'enjtão'),\n",
       " ('criar', 'criôar'),\n",
       " ('código', 'cóàigo'),\n",
       " ('caso', 'èaso'),\n",
       " ('exemplo', 'exbemplo'),\n",
       " ('tem', 'túem'),\n",
       " ('usuário', 'usuárin'),\n",
       " ('dados', 'daáos'),\n",
       " ('python', 'pythoçn'),\n",
       " ('nossa', 'nossk'),\n",
       " ('além', 'âlém'),\n",
       " ('assim', 'aóssim'),\n",
       " ('ter', 'tãer'),\n",
       " ('até', 'vté'),\n",
       " ('bem', 'búm'),\n",
       " ('design', 'íesign'),\n",
       " ('trabalho', 'trabèalho'),\n",
       " ('foi', 'kfoi'),\n",
       " ('apenas', 'aapenas'),\n",
       " ('empresa', 'pmpresa'),\n",
       " ('valor', 'valoqr'),\n",
       " ('será', 'sçerá'),\n",
       " ('entre', 'entró'),\n",
       " ('método', 'nétodo'),\n",
       " ('precisamos', 'prefcisamos'),\n",
       " ('ainda', 'sainda'),\n",
       " ('vai', 'uai'),\n",
       " ('conteúdo', 'cĩonteúdo'),\n",
       " ('seus', 'sâus'),\n",
       " ('eu', 'ìeu'),\n",
       " ('todos', 'todás'),\n",
       " ('tempo', 'utempo'),\n",
       " ('sempre', 'sempce'),\n",
       " ('qual', 'fual'),\n",
       " ('ela', 'elal'),\n",
       " ('só', 'skó'),\n",
       " ('utilizar', 'utilĩzar'),\n",
       " ('projeto', 'proójeto'),\n",
       " ('site', 'isite'),\n",
       " ('sem', 'secm'),\n",
       " ('pelo', 'pẽlo'),\n",
       " ('alura', 'aluéa'),\n",
       " ('dia', 'dil'),\n",
       " ('tudo', 'tudy'),\n",
       " ('ela', 'qelay'),\n",
       " ('só', 'sód'),\n",
       " ('utilizar', 'dtilizacr'),\n",
       " ('projeto', 'bprojõto'),\n",
       " ('site', 'ysiteo'),\n",
       " ('sem', 'sõêm'),\n",
       " ('pelo', 'peàli'),\n",
       " ('alura', 'asuraó'),\n",
       " ('dia', 'deiìa'),\n",
       " ('tudo', 'tuĩdoì'),\n",
       " ('ela', 'eúaa'),\n",
       " ('só', 'ró'),\n",
       " ('utilizar', 'utilizẽaçr'),\n",
       " ('projeto', 'prêjetó'),\n",
       " ('site', 'sqiqte'),\n",
       " ('sem', 'sũexm'),\n",
       " ('pelo', 'pçlxo'),\n",
       " ('alura', 'uluraa'),\n",
       " ('dia', 'dĩaz'),\n",
       " ('tudo', 'kzudo'),\n",
       " ('corretor', 'correptor'),\n",
       " ('tática', 'trtica'),\n",
       " ('empoderamento', 'ewpoderamento'),\n",
       " ('linux', 'lifux'),\n",
       " ('cachorro', 'cachoçro'),\n",
       " ('gato', 'îgato'),\n",
       " ('cavalo', 'cakvalo'),\n",
       " ('relógio', 'relógiuo'),\n",
       " ('canela', 'canelac'),\n",
       " ('tênis', 'tênisy'),\n",
       " ('ansiosa', 'anciosa'),\n",
       " ('ansiosa', 'ancciosa'),\n",
       " ('ansiosa', 'ansioa'),\n",
       " ('empoderamento', 'empoderamento'),\n",
       " ('asterisco', 'asterístico'),\n",
       " ('gratuito', 'gratuíto'),\n",
       " ('entretido', 'entertido'),\n",
       " ('ritmo', 'ritimo'),\n",
       " ('idiota', 'indiota'),\n",
       " ('tomara', 'tomare'),\n",
       " ('seja', 'seje'),\n",
       " ('prevalecer', 'provalecer'),\n",
       " ('esteja', 'esteje'),\n",
       " ('mendigo', 'mindigo'),\n",
       " ('cérebro', 'célebro'),\n",
       " ('perturbar', 'pertubar')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_datatest(file_name): # função que abre um arquivo txt, lê e separa as palavras de cada linha do arquivo armazenando-as em uma lista de tuplas.\n",
    "    test_words_list = []\n",
    "    f = open(file_name, 'r', encoding = 'UTF-8')\n",
    "    for line in f:\n",
    "        correct, wrong = line.split()\n",
    "        test_words_list.append((correct, wrong))\n",
    "    f.close()\n",
    "    return test_words_list\n",
    "\n",
    "test_list = create_datatest('./corretor-master/palavras.txt')\n",
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.08% de 186 palavras.\n"
     ]
    }
   ],
   "source": [
    "def corrector_analysis(test): # função que irá verificar a porcentagem de palavras que a função corrector() consegue corrigir em um determinado arquivo txt.\n",
    "    words_number = len(test)\n",
    "    corrections = 0\n",
    "    for correct_word, wrong_word in test:\n",
    "        corrected_word = corrector(wrong_word)\n",
    "        if corrected_word == correct_word:\n",
    "            corrections += 1\n",
    "    accuracy_rate = round((corrections * 100) / words_number, 2)\n",
    "    print(f'{accuracy_rate}% de {words_number} palavras.')\n",
    "\n",
    "corrector_analysis(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementando o delete de caracteres\n",
    "def delete_char(detached_word):\n",
    "    new_words = []\n",
    "    for left_side, right_side in detached_word:\n",
    "            new_words.append(left_side + right_side[1:]) \n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alóigica', 'blóigica', 'clóigica', 'dlóigica', 'elóigica', 'flóigica', 'glóigica', 'hlóigica', 'ilóigica', 'jlóigica', 'klóigica', 'llóigica', 'mlóigica', 'nlóigica', 'olóigica', 'plóigica', 'qlóigica', 'rlóigica', 'slóigica', 'tlóigica', 'ulóigica', 'vlóigica', 'wlóigica', 'xlóigica', 'ylóigica', 'zlóigica', 'àlóigica', 'álóigica', 'âlóigica', 'ãlóigica', 'èlóigica', 'élóigica', 'êlóigica', 'ìlóigica', 'ílóigica', 'îlóigica', 'òlóigica', 'ólóigica', 'ôlóigica', 'õlóigica', 'ùlóigica', 'úlóigica', 'ûlóigica', 'çlóigica', 'laóigica', 'lbóigica', 'lcóigica', 'ldóigica', 'leóigica', 'lfóigica', 'lgóigica', 'lhóigica', 'lióigica', 'ljóigica', 'lkóigica', 'llóigica', 'lmóigica', 'lnóigica', 'loóigica', 'lpóigica', 'lqóigica', 'lróigica', 'lsóigica', 'ltóigica', 'luóigica', 'lvóigica', 'lwóigica', 'lxóigica', 'lyóigica', 'lzóigica', 'làóigica', 'láóigica', 'lâóigica', 'lãóigica', 'lèóigica', 'léóigica', 'lêóigica', 'lìóigica', 'líóigica', 'lîóigica', 'lòóigica', 'lóóigica', 'lôóigica', 'lõóigica', 'lùóigica', 'lúóigica', 'lûóigica', 'lçóigica', 'lóaigica', 'lóbigica', 'lócigica', 'lódigica', 'lóeigica', 'lófigica', 'lógigica', 'lóhigica', 'lóiigica', 'lójigica', 'lókigica', 'lóligica', 'lómigica', 'lónigica', 'lóoigica', 'lópigica', 'lóqigica', 'lórigica', 'lósigica', 'lótigica', 'lóuigica', 'lóvigica', 'lówigica', 'lóxigica', 'lóyigica', 'lózigica', 'lóàigica', 'lóáigica', 'lóâigica', 'lóãigica', 'lóèigica', 'lóéigica', 'lóêigica', 'lóìigica', 'lóíigica', 'lóîigica', 'lóòigica', 'lóóigica', 'lóôigica', 'lóõigica', 'lóùigica', 'lóúigica', 'lóûigica', 'lóçigica', 'lóiagica', 'lóibgica', 'lóicgica', 'lóidgica', 'lóiegica', 'lóifgica', 'lóiggica', 'lóihgica', 'lóiigica', 'lóijgica', 'lóikgica', 'lóilgica', 'lóimgica', 'lóingica', 'lóiogica', 'lóipgica', 'lóiqgica', 'lóirgica', 'lóisgica', 'lóitgica', 'lóiugica', 'lóivgica', 'lóiwgica', 'lóixgica', 'lóiygica', 'lóizgica', 'lóiàgica', 'lóiágica', 'lóiâgica', 'lóiãgica', 'lóiègica', 'lóiégica', 'lóiêgica', 'lóiìgica', 'lóiígica', 'lóiîgica', 'lóiògica', 'lóiógica', 'lóiôgica', 'lóiõgica', 'lóiùgica', 'lóiúgica', 'lóiûgica', 'lóiçgica', 'lóigaica', 'lóigbica', 'lóigcica', 'lóigdica', 'lóigeica', 'lóigfica', 'lóiggica', 'lóighica', 'lóigiica', 'lóigjica', 'lóigkica', 'lóiglica', 'lóigmica', 'lóignica', 'lóigoica', 'lóigpica', 'lóigqica', 'lóigrica', 'lóigsica', 'lóigtica', 'lóiguica', 'lóigvica', 'lóigwica', 'lóigxica', 'lóigyica', 'lóigzica', 'lóigàica', 'lóigáica', 'lóigâica', 'lóigãica', 'lóigèica', 'lóigéica', 'lóigêica', 'lóigìica', 'lóigíica', 'lóigîica', 'lóigòica', 'lóigóica', 'lóigôica', 'lóigõica', 'lóigùica', 'lóigúica', 'lóigûica', 'lóigçica', 'lóigiaca', 'lóigibca', 'lóigicca', 'lóigidca', 'lóigieca', 'lóigifca', 'lóigigca', 'lóigihca', 'lóigiica', 'lóigijca', 'lóigikca', 'lóigilca', 'lóigimca', 'lóiginca', 'lóigioca', 'lóigipca', 'lóigiqca', 'lóigirca', 'lóigisca', 'lóigitca', 'lóigiuca', 'lóigivca', 'lóigiwca', 'lóigixca', 'lóigiyca', 'lóigizca', 'lóigiàca', 'lóigiáca', 'lóigiâca', 'lóigiãca', 'lóigièca', 'lóigiéca', 'lóigiêca', 'lóigiìca', 'lóigiíca', 'lóigiîca', 'lóigiòca', 'lóigióca', 'lóigiôca', 'lóigiõca', 'lóigiùca', 'lóigiúca', 'lóigiûca', 'lóigiçca', 'lóigicaa', 'lóigicba', 'lóigicca', 'lóigicda', 'lóigicea', 'lóigicfa', 'lóigicga', 'lóigicha', 'lóigicia', 'lóigicja', 'lóigicka', 'lóigicla', 'lóigicma', 'lóigicna', 'lóigicoa', 'lóigicpa', 'lóigicqa', 'lóigicra', 'lóigicsa', 'lóigicta', 'lóigicua', 'lóigicva', 'lóigicwa', 'lóigicxa', 'lóigicya', 'lóigicza', 'lóigicàa', 'lóigicáa', 'lóigicâa', 'lóigicãa', 'lóigicèa', 'lóigicéa', 'lóigicêa', 'lóigicìa', 'lóigicía', 'lóigicîa', 'lóigicòa', 'lóigicóa', 'lóigicôa', 'lóigicõa', 'lóigicùa', 'lóigicúa', 'lóigicûa', 'lóigicça', 'lóigicaa', 'lóigicab', 'lóigicac', 'lóigicad', 'lóigicae', 'lóigicaf', 'lóigicag', 'lóigicah', 'lóigicai', 'lóigicaj', 'lóigicak', 'lóigical', 'lóigicam', 'lóigican', 'lóigicao', 'lóigicap', 'lóigicaq', 'lóigicar', 'lóigicas', 'lóigicat', 'lóigicau', 'lóigicav', 'lóigicaw', 'lóigicax', 'lóigicay', 'lóigicaz', 'lóigicaà', 'lóigicaá', 'lóigicaâ', 'lóigicaã', 'lóigicaè', 'lóigicaé', 'lóigicaê', 'lóigicaì', 'lóigicaí', 'lóigicaî', 'lóigicaò', 'lóigicaó', 'lóigicaô', 'lóigicaõ', 'lóigicaù', 'lóigicaú', 'lóigicaû', 'lóigicaç', 'óigica', 'ligica', 'lógica', 'lóiica', 'lóigca', 'lóigia', 'lóigic', 'lóigica']\n"
     ]
    }
   ],
   "source": [
    "# adaptando a função word_generator() para incluir a recém criada função delete_char()\n",
    "def word_generator(word):\n",
    "    detached_word = []\n",
    "    for i in range(len(word) + 1): # adiciona-se o +1 para poder incluir o último item da lista na separação.\n",
    "        detached_word.append((word[:i], word[i:]))\n",
    "    \n",
    "    generated_words = insert_letters(detached_word)\n",
    "    generated_words += delete_char(detached_word) # implementação do delete_char()\n",
    "    return generated_words\n",
    "\n",
    "example_word = 'lóigica'\n",
    "generated_words = word_generator(example_word)\n",
    "print(generated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.4% de 186 palavras.\n"
     ]
    }
   ],
   "source": [
    "corrector_analysis(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementando a troca de letras\n",
    "def exchange_char(detached_word):\n",
    "    new_words = []\n",
    "    alphabet = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for left_side, right_side in detached_word:\n",
    "        for letter in alphabet:\n",
    "            new_words.append(left_side + letter + right_side[1:]) \n",
    "    return new_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alóigica', 'blóigica', 'clóigica', 'dlóigica', 'elóigica', 'flóigica', 'glóigica', 'hlóigica', 'ilóigica', 'jlóigica', 'klóigica', 'llóigica', 'mlóigica', 'nlóigica', 'olóigica', 'plóigica', 'qlóigica', 'rlóigica', 'slóigica', 'tlóigica', 'ulóigica', 'vlóigica', 'wlóigica', 'xlóigica', 'ylóigica', 'zlóigica', 'àlóigica', 'álóigica', 'âlóigica', 'ãlóigica', 'èlóigica', 'élóigica', 'êlóigica', 'ìlóigica', 'ílóigica', 'îlóigica', 'òlóigica', 'ólóigica', 'ôlóigica', 'õlóigica', 'ùlóigica', 'úlóigica', 'ûlóigica', 'çlóigica', 'laóigica', 'lbóigica', 'lcóigica', 'ldóigica', 'leóigica', 'lfóigica', 'lgóigica', 'lhóigica', 'lióigica', 'ljóigica', 'lkóigica', 'llóigica', 'lmóigica', 'lnóigica', 'loóigica', 'lpóigica', 'lqóigica', 'lróigica', 'lsóigica', 'ltóigica', 'luóigica', 'lvóigica', 'lwóigica', 'lxóigica', 'lyóigica', 'lzóigica', 'làóigica', 'láóigica', 'lâóigica', 'lãóigica', 'lèóigica', 'léóigica', 'lêóigica', 'lìóigica', 'líóigica', 'lîóigica', 'lòóigica', 'lóóigica', 'lôóigica', 'lõóigica', 'lùóigica', 'lúóigica', 'lûóigica', 'lçóigica', 'lóaigica', 'lóbigica', 'lócigica', 'lódigica', 'lóeigica', 'lófigica', 'lógigica', 'lóhigica', 'lóiigica', 'lójigica', 'lókigica', 'lóligica', 'lómigica', 'lónigica', 'lóoigica', 'lópigica', 'lóqigica', 'lórigica', 'lósigica', 'lótigica', 'lóuigica', 'lóvigica', 'lówigica', 'lóxigica', 'lóyigica', 'lózigica', 'lóàigica', 'lóáigica', 'lóâigica', 'lóãigica', 'lóèigica', 'lóéigica', 'lóêigica', 'lóìigica', 'lóíigica', 'lóîigica', 'lóòigica', 'lóóigica', 'lóôigica', 'lóõigica', 'lóùigica', 'lóúigica', 'lóûigica', 'lóçigica', 'lóiagica', 'lóibgica', 'lóicgica', 'lóidgica', 'lóiegica', 'lóifgica', 'lóiggica', 'lóihgica', 'lóiigica', 'lóijgica', 'lóikgica', 'lóilgica', 'lóimgica', 'lóingica', 'lóiogica', 'lóipgica', 'lóiqgica', 'lóirgica', 'lóisgica', 'lóitgica', 'lóiugica', 'lóivgica', 'lóiwgica', 'lóixgica', 'lóiygica', 'lóizgica', 'lóiàgica', 'lóiágica', 'lóiâgica', 'lóiãgica', 'lóiègica', 'lóiégica', 'lóiêgica', 'lóiìgica', 'lóiígica', 'lóiîgica', 'lóiògica', 'lóiógica', 'lóiôgica', 'lóiõgica', 'lóiùgica', 'lóiúgica', 'lóiûgica', 'lóiçgica', 'lóigaica', 'lóigbica', 'lóigcica', 'lóigdica', 'lóigeica', 'lóigfica', 'lóiggica', 'lóighica', 'lóigiica', 'lóigjica', 'lóigkica', 'lóiglica', 'lóigmica', 'lóignica', 'lóigoica', 'lóigpica', 'lóigqica', 'lóigrica', 'lóigsica', 'lóigtica', 'lóiguica', 'lóigvica', 'lóigwica', 'lóigxica', 'lóigyica', 'lóigzica', 'lóigàica', 'lóigáica', 'lóigâica', 'lóigãica', 'lóigèica', 'lóigéica', 'lóigêica', 'lóigìica', 'lóigíica', 'lóigîica', 'lóigòica', 'lóigóica', 'lóigôica', 'lóigõica', 'lóigùica', 'lóigúica', 'lóigûica', 'lóigçica', 'lóigiaca', 'lóigibca', 'lóigicca', 'lóigidca', 'lóigieca', 'lóigifca', 'lóigigca', 'lóigihca', 'lóigiica', 'lóigijca', 'lóigikca', 'lóigilca', 'lóigimca', 'lóiginca', 'lóigioca', 'lóigipca', 'lóigiqca', 'lóigirca', 'lóigisca', 'lóigitca', 'lóigiuca', 'lóigivca', 'lóigiwca', 'lóigixca', 'lóigiyca', 'lóigizca', 'lóigiàca', 'lóigiáca', 'lóigiâca', 'lóigiãca', 'lóigièca', 'lóigiéca', 'lóigiêca', 'lóigiìca', 'lóigiíca', 'lóigiîca', 'lóigiòca', 'lóigióca', 'lóigiôca', 'lóigiõca', 'lóigiùca', 'lóigiúca', 'lóigiûca', 'lóigiçca', 'lóigicaa', 'lóigicba', 'lóigicca', 'lóigicda', 'lóigicea', 'lóigicfa', 'lóigicga', 'lóigicha', 'lóigicia', 'lóigicja', 'lóigicka', 'lóigicla', 'lóigicma', 'lóigicna', 'lóigicoa', 'lóigicpa', 'lóigicqa', 'lóigicra', 'lóigicsa', 'lóigicta', 'lóigicua', 'lóigicva', 'lóigicwa', 'lóigicxa', 'lóigicya', 'lóigicza', 'lóigicàa', 'lóigicáa', 'lóigicâa', 'lóigicãa', 'lóigicèa', 'lóigicéa', 'lóigicêa', 'lóigicìa', 'lóigicía', 'lóigicîa', 'lóigicòa', 'lóigicóa', 'lóigicôa', 'lóigicõa', 'lóigicùa', 'lóigicúa', 'lóigicûa', 'lóigicça', 'lóigicaa', 'lóigicab', 'lóigicac', 'lóigicad', 'lóigicae', 'lóigicaf', 'lóigicag', 'lóigicah', 'lóigicai', 'lóigicaj', 'lóigicak', 'lóigical', 'lóigicam', 'lóigican', 'lóigicao', 'lóigicap', 'lóigicaq', 'lóigicar', 'lóigicas', 'lóigicat', 'lóigicau', 'lóigicav', 'lóigicaw', 'lóigicax', 'lóigicay', 'lóigicaz', 'lóigicaà', 'lóigicaá', 'lóigicaâ', 'lóigicaã', 'lóigicaè', 'lóigicaé', 'lóigicaê', 'lóigicaì', 'lóigicaí', 'lóigicaî', 'lóigicaò', 'lóigicaó', 'lóigicaô', 'lóigicaõ', 'lóigicaù', 'lóigicaú', 'lóigicaû', 'lóigicaç', 'óigica', 'ligica', 'lógica', 'lóiica', 'lóigca', 'lóigia', 'lóigic', 'lóigica', 'aóigica', 'bóigica', 'cóigica', 'dóigica', 'eóigica', 'fóigica', 'góigica', 'hóigica', 'ióigica', 'jóigica', 'kóigica', 'lóigica', 'móigica', 'nóigica', 'oóigica', 'póigica', 'qóigica', 'róigica', 'sóigica', 'tóigica', 'uóigica', 'vóigica', 'wóigica', 'xóigica', 'yóigica', 'zóigica', 'àóigica', 'áóigica', 'âóigica', 'ãóigica', 'èóigica', 'éóigica', 'êóigica', 'ìóigica', 'íóigica', 'îóigica', 'òóigica', 'óóigica', 'ôóigica', 'õóigica', 'ùóigica', 'úóigica', 'ûóigica', 'çóigica', 'laigica', 'lbigica', 'lcigica', 'ldigica', 'leigica', 'lfigica', 'lgigica', 'lhigica', 'liigica', 'ljigica', 'lkigica', 'lligica', 'lmigica', 'lnigica', 'loigica', 'lpigica', 'lqigica', 'lrigica', 'lsigica', 'ltigica', 'luigica', 'lvigica', 'lwigica', 'lxigica', 'lyigica', 'lzigica', 'làigica', 'láigica', 'lâigica', 'lãigica', 'lèigica', 'léigica', 'lêigica', 'lìigica', 'líigica', 'lîigica', 'lòigica', 'lóigica', 'lôigica', 'lõigica', 'lùigica', 'lúigica', 'lûigica', 'lçigica', 'lóagica', 'lóbgica', 'lócgica', 'lódgica', 'lóegica', 'lófgica', 'lóggica', 'lóhgica', 'lóigica', 'lójgica', 'lókgica', 'lólgica', 'lómgica', 'lóngica', 'lóogica', 'lópgica', 'lóqgica', 'lórgica', 'lósgica', 'lótgica', 'lóugica', 'lóvgica', 'lówgica', 'lóxgica', 'lóygica', 'lózgica', 'lóàgica', 'lóágica', 'lóâgica', 'lóãgica', 'lóègica', 'lóégica', 'lóêgica', 'lóìgica', 'lóígica', 'lóîgica', 'lóògica', 'lóógica', 'lóôgica', 'lóõgica', 'lóùgica', 'lóúgica', 'lóûgica', 'lóçgica', 'lóiaica', 'lóibica', 'lóicica', 'lóidica', 'lóieica', 'lóifica', 'lóigica', 'lóihica', 'lóiiica', 'lóijica', 'lóikica', 'lóilica', 'lóimica', 'lóinica', 'lóioica', 'lóipica', 'lóiqica', 'lóirica', 'lóisica', 'lóitica', 'lóiuica', 'lóivica', 'lóiwica', 'lóixica', 'lóiyica', 'lóizica', 'lóiàica', 'lóiáica', 'lóiâica', 'lóiãica', 'lóièica', 'lóiéica', 'lóiêica', 'lóiìica', 'lóiíica', 'lóiîica', 'lóiòica', 'lóióica', 'lóiôica', 'lóiõica', 'lóiùica', 'lóiúica', 'lóiûica', 'lóiçica', 'lóigaca', 'lóigbca', 'lóigcca', 'lóigdca', 'lóigeca', 'lóigfca', 'lóiggca', 'lóighca', 'lóigica', 'lóigjca', 'lóigkca', 'lóiglca', 'lóigmca', 'lóignca', 'lóigoca', 'lóigpca', 'lóigqca', 'lóigrca', 'lóigsca', 'lóigtca', 'lóiguca', 'lóigvca', 'lóigwca', 'lóigxca', 'lóigyca', 'lóigzca', 'lóigàca', 'lóigáca', 'lóigâca', 'lóigãca', 'lóigèca', 'lóigéca', 'lóigêca', 'lóigìca', 'lóigíca', 'lóigîca', 'lóigòca', 'lóigóca', 'lóigôca', 'lóigõca', 'lóigùca', 'lóigúca', 'lóigûca', 'lóigçca', 'lóigiaa', 'lóigiba', 'lóigica', 'lóigida', 'lóigiea', 'lóigifa', 'lóigiga', 'lóigiha', 'lóigiia', 'lóigija', 'lóigika', 'lóigila', 'lóigima', 'lóigina', 'lóigioa', 'lóigipa', 'lóigiqa', 'lóigira', 'lóigisa', 'lóigita', 'lóigiua', 'lóigiva', 'lóigiwa', 'lóigixa', 'lóigiya', 'lóigiza', 'lóigiàa', 'lóigiáa', 'lóigiâa', 'lóigiãa', 'lóigièa', 'lóigiéa', 'lóigiêa', 'lóigiìa', 'lóigiía', 'lóigiîa', 'lóigiòa', 'lóigióa', 'lóigiôa', 'lóigiõa', 'lóigiùa', 'lóigiúa', 'lóigiûa', 'lóigiça', 'lóigica', 'lóigicb', 'lóigicc', 'lóigicd', 'lóigice', 'lóigicf', 'lóigicg', 'lóigich', 'lóigici', 'lóigicj', 'lóigick', 'lóigicl', 'lóigicm', 'lóigicn', 'lóigico', 'lóigicp', 'lóigicq', 'lóigicr', 'lóigics', 'lóigict', 'lóigicu', 'lóigicv', 'lóigicw', 'lóigicx', 'lóigicy', 'lóigicz', 'lóigicà', 'lóigicá', 'lóigicâ', 'lóigicã', 'lóigicè', 'lóigicé', 'lóigicê', 'lóigicì', 'lóigicí', 'lóigicî', 'lóigicò', 'lóigicó', 'lóigicô', 'lóigicõ', 'lóigicù', 'lóigicú', 'lóigicû', 'lóigicç', 'lóigicaa', 'lóigicab', 'lóigicac', 'lóigicad', 'lóigicae', 'lóigicaf', 'lóigicag', 'lóigicah', 'lóigicai', 'lóigicaj', 'lóigicak', 'lóigical', 'lóigicam', 'lóigican', 'lóigicao', 'lóigicap', 'lóigicaq', 'lóigicar', 'lóigicas', 'lóigicat', 'lóigicau', 'lóigicav', 'lóigicaw', 'lóigicax', 'lóigicay', 'lóigicaz', 'lóigicaà', 'lóigicaá', 'lóigicaâ', 'lóigicaã', 'lóigicaè', 'lóigicaé', 'lóigicaê', 'lóigicaì', 'lóigicaí', 'lóigicaî', 'lóigicaò', 'lóigicaó', 'lóigicaô', 'lóigicaõ', 'lóigicaù', 'lóigicaú', 'lóigicaû', 'lóigicaç', 'óligica', 'liógica', 'lógiica', 'lóiigca', 'lóigcia', 'lóigiac']\n"
     ]
    }
   ],
   "source": [
    "def insert_letters(detached_word):\n",
    "    new_words = []\n",
    "    alphabet = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for left_side, right_side in detached_word:\n",
    "        for letter in alphabet:\n",
    "            new_words.append(left_side + letter + right_side) \n",
    "    return new_words\n",
    "\n",
    "# implementando o delete de caracteres\n",
    "def delete_char(detached_word):\n",
    "    new_words = []\n",
    "    for left_side, right_side in detached_word:\n",
    "            new_words.append(left_side + right_side[1:]) \n",
    "    return new_words\n",
    "\n",
    "# Implementando a troca de letras\n",
    "def exchange_char(detached_word):\n",
    "    new_words = []\n",
    "    alphabet = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for left_side, right_side in detached_word:\n",
    "        for letter in alphabet:\n",
    "            new_words.append(left_side + letter + right_side[1:]) \n",
    "    return new_words\n",
    "\n",
    "# implementando a inversão de caracteres\n",
    "def invert_char(detached_word):\n",
    "    new_words = []\n",
    "    for left_side, right_side in detached_word:\n",
    "        if len(right_side) > 1:\n",
    "            new_words.append(left_side + right_side[1] + right_side[0] + right_side[2:]) \n",
    "    return new_words\n",
    "\n",
    "# adaptando a função word_generator() para incluir delete_char(), exchange_char() e invert_char()\n",
    "def word_generator(word):\n",
    "    detached_word = []\n",
    "    for i in range(len(word) + 1): # adiciona-se o +1 para poder incluir o último item da lista na separação.\n",
    "        detached_word.append((word[:i], word[i:]))\n",
    "    \n",
    "    generated_words = insert_letters(detached_word)\n",
    "    generated_words += delete_char(detached_word) # implementação do delete_char()\n",
    "    generated_words += exchange_char(detached_word) # implementação do exchange_char()\n",
    "    generated_words += invert_char(detached_word) # implementação do invert_char()\n",
    "    return generated_words\n",
    "\n",
    "example_word = 'lóigica'\n",
    "generated_words = word_generator(example_word)\n",
    "print(generated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.34% de 186 palavras.\n"
     ]
    }
   ],
   "source": [
    "corrector_analysis(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.34% de 186 palavras. Desconhecida é 6.99%.\n"
     ]
    }
   ],
   "source": [
    "def corrector_analysis(test, vocabulary): # função que irá verificar a porcentagem de palavras que a função corrector() consegue corrigir em um determinado arquivo txt.\n",
    "    words_number = len(test)\n",
    "    corrections = 0\n",
    "    unknown = 0\n",
    "    for correct_word, wrong_word in test:\n",
    "        corrected_word = corrector(wrong_word)\n",
    "        unknown += (correct_word not in vocabulary)\n",
    "        if corrected_word == correct_word:\n",
    "            corrections += 1\n",
    "\n",
    "    accuracy_rate = round((corrections * 100) / words_number, 2)\n",
    "    unknown_rate = round((unknown * 100) / words_number, 2)\n",
    "    print(f'{accuracy_rate}% de {words_number} palavras. Desconhecida é {unknown_rate}%.')\n",
    "\n",
    "vocabulary = set(normalized_list)\n",
    "corrector_analysis(test_list, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'lóiigica'\n",
    "def robust_word_generator(generated_words):\n",
    "    new_words = []\n",
    "    for word in generated_words:\n",
    "        new_words += word_generator(word)\n",
    "    return new_words\n",
    "\n",
    "g_words = robust_word_generator(word_generator(word))\n",
    "'lógica' in g_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "691744"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def new_corrector(word):\n",
    "    generated_words = word_generator(word)\n",
    "    robust_generated_words = robust_word_generator(generated_words)\n",
    "    all_words = set(generated_words + robust_generated_words)\n",
    "    candidate = [word]\n",
    "    for word in all_words:\n",
    "        if word in vocabulary:\n",
    "            candidate.append(word)\n",
    "    \n",
    "    correct_word = max(candidate, key = probability)\n",
    "    return correct_word\n",
    "\n",
    "new_corrector(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.38% de 186 palavras. Desconhecida é 6.99%.\n"
     ]
    }
   ],
   "source": [
    "def new_corrector_analysis(test, vocabulary): # função que irá verificar a porcentagem de palavras que a função corrector() consegue corrigir em um determinado arquivo txt.\n",
    "    words_number = len(test)\n",
    "    corrections = 0\n",
    "    unknown = 0\n",
    "    for correct_word, wrong_word in test:\n",
    "        corrected_word = new_corrector(wrong_word)\n",
    "        unknown += (correct_word not in vocabulary)\n",
    "        if corrected_word == correct_word:\n",
    "            corrections += 1\n",
    "\n",
    "    accuracy_rate = round((corrections * 100) / words_number, 2)\n",
    "    unknown_rate = round((unknown * 100) / words_number, 2)\n",
    "    print(f'{accuracy_rate}% de {words_number} palavras. Desconhecida é {unknown_rate}%.')\n",
    "\n",
    "vocabulary = set(normalized_list)\n",
    "new_corrector_analysis(test_list, vocabulary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "427b8541cfc07e6fbe7ab4a5298567b1b3022ff2b70fdb07d029f33f0434686a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
